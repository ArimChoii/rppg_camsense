{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "class FaceDetect:\n",
    "    def __init__(self, video_path=None, sav_opt=0, filename=[]):\n",
    "        self.video_path = video_path\n",
    "        self.face_cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "        self.eye_cascade = cv2.CascadeClassifier(\"./haarcascade_eye.xml\")\n",
    "        self.cap = cv2.VideoCapture(self.video_path)\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.sav_opt = sav_opt  \n",
    "        self.filename = filename\n",
    "        self.cheek = []\n",
    "\n",
    "    def butter_lowpass(self, cutoff, fs, order=5):\n",
    "        nyq = 0.3 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "\n",
    "    def butter_lowpass_filter(self, data, cutoff, fs, order=5):\n",
    "        b, a = self.butter_lowpass(cutoff, fs, order=order)\n",
    "        y = filtfilt(b, a, data)\n",
    "        return y\n",
    "        \n",
    "    def butter_bandpass(self, lowcut, highcut, fs, order=5):\n",
    "        nyq = (0.3 * fs)\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "\n",
    "    def butter_bandpass_filter(self, data, lowcut, highcut, fs, order=5):\n",
    "        b, a = self.butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = filtfilt(b, a, data)\n",
    "        return y\n",
    "\n",
    "    def run_vid(self):\n",
    "        cropmn = []\n",
    "        frame_count = 0        \n",
    "        i = 0\n",
    "        pixel_values = []\n",
    "        time_values = []\n",
    "        red = []\n",
    "        green = []\n",
    "        blue = []\n",
    "        \n",
    "        while frame_count < int(10 * self.fps): #control the time that spend for reading\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #gray=cv2.cvtColor\n",
    "            # face detection with face_cascade\n",
    "            faces = self.face_cascade.detectMultiScale(\n",
    "                    gray,\n",
    "                    scaleFactor=1.1,\n",
    "                    minNeighbors=5,\n",
    "                    minSize = (30,30),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                    )\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, \"Detected Face\", (x - 5, y - 5), cv2.FONT_ITALIC, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "                face_image = frame[y:y + h, x:x + w]\n",
    "                cropmn.append(face_image)  \n",
    "                \n",
    "                cv2.imshow(\"Detected face\", face_image)\n",
    "                \n",
    "                [a, b, c, d] = [9 * w // 10, h // 2, 5 * w // 5, 2 * h // 3]  #space that I assigned\n",
    "                cv2.rectangle(face_image, (a, b), (c, d), (255, 255, 255))\n",
    "                cheekimg = face_image[b:d, a:c]\n",
    "                \n",
    "                cv2.imshow(\"cheekimg \", cheekimg)\n",
    "                \n",
    "                self.cheek.append(cheekimg.mean()) \n",
    "\n",
    "                # Calculate the center point of the cheekimg rectangle by the facial mask\n",
    "                center_x = 35 * w // 50  # Calculate center x\n",
    "                center_y = 25 * h // 60  # Calculate center y\n",
    "            \n",
    "                # Extract a 7x7 region around the center point\n",
    "                roi_size = 3  # Half-size of the ROI, 7x7 requires 3 pixels around the center\n",
    "                roi = face_image[max(center_y - roi_size, 0):min(center_y + roi_size + 1, face_image.shape[0]),\n",
    "                                 max(center_x - roi_size, 0):min(center_x + roi_size + 1, face_image.shape[1])]\n",
    "            \n",
    "                # Calculate average color values in the ROI\n",
    "                avg_color_per_row = np.average(roi, axis=0)\n",
    "                avg_color = np.average(avg_color_per_row, axis=0)\n",
    "                avg_red, avg_green, avg_blue = avg_color[2], avg_color[1], avg_color[0]\n",
    "            \n",
    "                # Append the average values to the lists\n",
    "                red.append(avg_red)\n",
    "                green.append(avg_green)\n",
    "                blue.append(avg_blue)\n",
    "    \n",
    "                # Get the pixel value at the center point\n",
    "                pixel_value = face_image[center_y, center_x]  # Access pixel value\n",
    "                # Append the pixel value to the list\n",
    "                pixel_values.append(pixel_value)\n",
    "                \n",
    "                if i < len(self.cheek):\n",
    "                    time_values.append(frame_count / self.fps)\n",
    "                    red.append(face_image[center_y, center_x][2])  # Red channel\n",
    "                    green.append(face_image[center_y, center_x][1])  # Green channel\n",
    "                    blue.append(face_image[center_y, center_x][0])  # Blue channel\n",
    "\n",
    "            # Display the result\n",
    "            if cv2.waitKey(1) & 0xFF == 27 :\n",
    "                break\n",
    "                    \n",
    "            frame_count += 1\n",
    "            i += 1\n",
    "            time_values.append(frame_count / self.fps)\n",
    "    \n",
    "        cv2.destroyAllWindows()\n",
    "        self.cheek = np.array(self.cheek)\n",
    "        \n",
    "        # band-pass filter            \n",
    "        filtered_red = self.butter_bandpass_filter(red, 0.5, 3.0, self.fps)\n",
    "        filtered_green = self.butter_bandpass_filter(green, 0.5, 3.0, self.fps)\n",
    "        filtered_blue = self.butter_bandpass_filter(blue, 0.5, 3.0, self.fps)\n",
    "        \n",
    "        # low-pass filter\n",
    "        lowpass_cutoff = 2.5  # cutoff frequency (Hz)\n",
    "        lowpassed_red = self.butter_lowpass_filter(filtered_red, lowpass_cutoff, self.fps)\n",
    "        lowpassed_green = self.butter_lowpass_filter(filtered_green, lowpass_cutoff, self.fps)\n",
    "        lowpassed_blue = self.butter_lowpass_filter(filtered_blue, lowpass_cutoff, self.fps)\n",
    "\n",
    "        # Bandpass+low-pass filtered RGB\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(time_values, lowpassed_red, label='Band-pass+Low-passed Red', color='r')\n",
    "        plt.plot(time_values, lowpassed_green, label='Band-pass+Low-passed Green', color='g')\n",
    "        plt.plot(time_values, lowpassed_blue, label='Band-pass+Low-passed Blue', color='b')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Pixel Value')\n",
    "        plt.title('Bandpass and Low-pass Filtered RGB Channels Over Time')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        #filter finished\n",
    "        \n",
    "        #calculate HR with peak data (give more weight to Green chanel) \n",
    "        combined_signal = lowpassed_red + 10 * lowpassed_green + lowpassed_blue\n",
    "        peaks, _ = find_peaks(combined_signal)\n",
    "        intervals = np.diff(peaks) / self.fps\n",
    "        print(\"intervals\", intervals)\n",
    "        check_heart = 60 / intervals\n",
    "        print('heart rate per second', check_heart)\n",
    "\n",
    "        #average HR\n",
    "        if len(intervals) > 0:\n",
    "            avg_heart_rate = 60 / np.mean(intervals)\n",
    "        else:\n",
    "            avg_heart_rate = 0  # if there's no peak\n",
    "\n",
    "        if self.sav_opt:\n",
    "            self.vidwrit(i2s=self.cheek)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(time_values, combined_signal, label='Combined Signal', color='purple')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Pixel Value')\n",
    "        plt.title('Combined RGB Channels Over Time')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()  \n",
    "        #HR detection finished\n",
    "        \n",
    "        #지금 현재 5-10초 동안의 그래프 확인 \n",
    "        # Plot filtered RGB channels over the specific time interval\n",
    "        start_time = 15  # Start time in seconds\n",
    "        end_time = 30    # End time in seconds\n",
    "        start_index = int(start_time * self.fps)\n",
    "        end_index = int(end_time * self.fps)\n",
    "    \n",
    "        # Ensure indices are within the array bounds\n",
    "        start_index = min(start_index, len(filtered_red) - 1)\n",
    "        end_index = min(end_index, len(filtered_red))\n",
    "    \n",
    "        # Extracting slices for the specified time interval\n",
    "        time_slice = time_values[start_index:end_index]\n",
    "        red_slice = lowpassed_red[start_index:end_index]\n",
    "        green_slice = lowpassed_green[start_index:end_index]\n",
    "        blue_slice = lowpassed_blue[start_index:end_index]\n",
    "    \n",
    "        # Plotting the sliced data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        #plt.subplot(1, 1, 1)\n",
    "        plt.plot(time_slice, red_slice, label='Red', color='r')\n",
    "        plt.plot(time_slice, green_slice, label='Green', color='g')\n",
    "        plt.plot(time_slice, blue_slice, label='Blue', color='b')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Filtered Pixel Value')\n",
    "        plt.title('Filtered RGB Channels (Interval)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        limited_combined_signal = combined_signal[start_index:end_index]\n",
    "        #graph for combined_signal        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        #plt.subplot(1, 1, 2)\n",
    "        plt.plot(time_slice, limited_combined_signal, label='Combined Signal', color='purple')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Pixel Value')\n",
    "        plt.title('Limited Combined RGB Channels Over Time')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show() \n",
    "\n",
    "        return avg_heart_rate, self.cheek, pixel_values, red, blue, green\n",
    "\n",
    "    def vidwrit(self, i2s=[]):\n",
    "        out = cv2.VideoWriter(self.filename, cv2.VideoWriter_fourcc(*'DIVX'), self.fps, (200, 200))\n",
    "        for i in range(len(i2s)):\n",
    "            out.write(i2s[i])\n",
    "        out.release()\n",
    "    \n",
    "#call the vid\n",
    "vidname = './vid-48.avi'\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "videop =  FaceDetect(video_path=vidname, sav_opt=0, filename=vidname)\n",
    "\n",
    "avg_heart_rate, _, _, _, _, _ = videop.run_vid()\n",
    "print(\"vidname : \", vidname)\n",
    "print(f\"Average Estimated Heart Rate: {avg_heart_rate} BPM\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6b55c65d8d419cd4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
